# 🚀 使用 Stream 处理大文件，避免一次性加载内存

---

## ✅ 为什么要用 Stream？

Node.js 是基于事件循环的单线程模型，如果你读取一个大文件：

```js
// ❌ 不推荐
const data = fs.readFileSync('large.txt', 'utf8');
```

这个写法有两个严重问题：

1. **同步阻塞**：`readFileSync` 会卡住主线程；
2. **内存爆炸**：一次性把大文件（如 1GB 日志）读进内存，非常容易 OOM（内存溢出）。

---

## ✅ Stream 的核心优势

| 特点     | 描述                                                     |
| ------ | ------------------------------------------------------ |
| 分段读取   | 数据被分成小块（chunk）处理，降低内存                                  |
| 异步非阻塞  | 使用事件监听，不卡住主线程                                          |
| 流式处理   | 可边读取边写入，边转码边传输                                         |
| 节点级别支持 | 原生 `fs.createReadStream`, `http`, `zlib`, `crypto` 都是流 |

---

## 📦 四种流类型（Node.js 原生 Stream）

1. **Readable**：可读流（读取文件）
2. **Writable**：可写流（写入文件）
3. **Duplex**：双向流（TCP）
4. **Transform**：转换流（gzip, 解密）

---

## ✅ 示例：用 Stream 读取大文件并发送响应

```js
const fs = require('fs');
const http = require('http');

http.createServer((req, res) => {
  const readStream = fs.createReadStream('./bigfile.txt');
  res.writeHead(200, { 'Content-Type': 'text/plain' });
  readStream.pipe(res); // ✅ 边读边传，不占内存
}).listen(3000);
```

✔️ 适合用于视频、日志、CSV 导出等大体积传输场景。

---

## ✅ 示例：流式处理 CSV 并逐行入库（避免爆内存）

```js
const fs = require('fs');
const readline = require('readline');

async function processCSV() {
  const fileStream = fs.createReadStream('./big.csv');

  const rl = readline.createInterface({
    input: fileStream,
    crlfDelay: Infinity
  });

  for await (const line of rl) {
    const values = line.split(',');
    await db.insert(values); // ✅ 控制逐条写入，不卡主线程
  }
}
```

---

## ❌ vs ❗ 常见误区：一次性读取很危险！

```js
// 会一次性加载到内存中，占用严重
const file = await fs.promises.readFile('./hugefile.csv', 'utf8');
```

即使是异步，但由于数据太大，**仍然可能压垮进程内存**。

---

## 🧠 实战场景对比

| 场景          | 普通方式             | 使用 Stream 的优势                 |
| ----------- | ---------------- | ----------------------------- |
| 日志下载        | 先读入内存再发送         | 可边读边发，支持无限大日志                 |
| 视频传输        | Base64 编码读取      | 使用 stream.pipe() 边传边缓存        |
| 上传大文件       | 使用 `busboy` 等解析流 | 节省临时磁盘 & 内存占用                 |
| 解压 zip/gzip | 解压后一次性读入         | 使用 `zlib.createGunzip()` 流式解压 |

---

## 🧰 常用工具链推荐

| 类型    | 工具/库                                 | 用途        |
| ----- | ------------------------------------ | --------- |
| 解析流文件 | `readline`, `csv-parser`, `fast-csv` | CSV / 文本流 |
| 上传文件  | `busboy`, `formidable`               | 大文件流式上传   |
| 压缩    | `zlib.createGzip()`                  | gzip 压缩流  |
| 下载    | `stream.pipeline`, `res.pipe()`      | 响应大文件流    |
| 转换    | `through2`, `stream.Transform`       | 自定义数据转换   |

---

## ✅ 总结最佳实践

| 项目     | 建议                                               |
| ------ | ------------------------------------------------ |
| 文件读取   | 尽量使用 `fs.createReadStream()` 替代 `fs.readFile()`  |
| 写入     | 用 `createWriteStream()` 替代一次性 `writeFile()`      |
| pipe链路 | `readable.pipe(transform).pipe(writable)` 是最标准写法 |
| 错误处理   | 使用 `.on('error')` 避免 silent fail                 |
| 回收资源   | 记得关闭流，或监听 `.on('close')`                         |

